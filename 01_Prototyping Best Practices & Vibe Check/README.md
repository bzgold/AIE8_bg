<p align = "center" draggable=”false” ><img src="https://github.com/AI-Maker-Space/LLM-Dev-101/assets/37101144/d1343317-fa2f-41e1-8af1-1dbb18399719" 
     width="200px"
     height="auto"/>
</p>

<h1 align="center" id="heading">Session 1: Introduction and Vibe Check</h1>

### [Quicklinks](https://github.com/AI-Maker-Space/AIE8/tree/main/00_AIM_Quicklinks)

| 📰 Session Sheet | ⏺️ Recording     | 🖼️ Slides        | 👨‍💻 Repo         | 📝 Homework      | 📁 Feedback       |
|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|:-----------------|
| [Session 1: Introduction and Vibe Check](https://www.notion.so/Session-1-Introduction-and-Vibe-Check-263cd547af3d81869041ccc46523f1ec) |[Recording!](https://us02web.zoom.us/rec/share/AZEoQtJn03hZUBXoaAUT9I1Nx7sSdsjZ4n5ll8TTfCGQsVrBi709FLQLXwwdCCxD.2YqwpkoZhDDnHVKK) (Y&W@%PS3) | [Session 1 Slides](https://www.canva.com/design/DAGya0dMFhM/I4kYi9Y-Ec_jMtoq0aq4-g/edit?utm_content=DAGya0dMFhM&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton) | You are here! | [Session 1 Assignment: Vibe Check](https://forms.gle/jNhHxcmCoMJiqpUL6) | [AIE8 Feedback 9/9](https://forms.gle/GgFqgEkYPQ5a3yHj7)

## 🏗️ How AIM Does Assignments

> 📅 **Assignments will always be released to students as live class begins.** We will never release assignments early.

Each assignment will have a few of the following categories of exercises:

- ❓ **Questions** – these will be questions that you will be expected to gather the answer to! These can appear as general questions, or questions meant to spark a discussion in your breakout rooms!

- 🏗️ **Activities** – these will be work or coding activities meant to reinforce specific concepts or theory components.

- 🚧 **Advanced Builds (optional)** – Take on a challenge! These builds require you to create something with minimal guidance outside of the documentation. Completing an Advanced Build earns full credit in place of doing the base assignment notebook questions/activities.

### Main Assignment

In the following assignment, you are required to take the app that you created for the AIE8 challenge (from [this repository](https://github.com/AI-Maker-Space/The-AI-Engineer-Challenge)) and conduct what is known, colloquially, as a "vibe check" on the application. 

You will be required to submit a link to your GitHub, as well as screenshots of the completed "vibe checks" through the provided Google Form!

> NOTE: This will require you to make updates to your personal class repository, instructions on that process can be found [here](https://github.com/AI-Maker-Space/AIE8/tree/main/00_Setting%20Up%20Git)!


#### 🏗️ Activity #1:

Please evaluate your system on the following questions:

1. Explain the concept of object-oriented programming in simple terms to a complete beginner. 
    - Aspect Tested: 
    
    
    In this case, this question is testing if the application can take a more complex term, understand the key elements of OOP, and communicate it in a simplified manner. The application did pass since the reply was high level and easy to understand. It also incorporated an example without being prompted to help the user understand the concept in a clear way. Also, since the prompt didn't state what type of beginner, the reply was general enough for all types of users and not just on technical personnel.  
    
    What could make the application better: the format (mix of bullets, short paragraphs, and **markdown style**) could be cleaned up to make it more readable. Also, instead of ending in "does that help?" the response could end with some clean leading questions - i.e. would you like another example? do you want more of a technical explanation?   





2. Read the following paragraph and provide a concise summary of the key points...
    - Aspect Tested: 

    I chose an article about the famous Fat Bear Week that occurs every year. 

            One sentence sumamry of the article: Fat Bear Week is a fun and engaging annual contest held at Katmai National Park where locals and viewers worldwide vote for the chunkiest bears as they prepare for hibernation, raising awareness about the brown bears and their vital role in the ecosystem.

    This question is testing the application's ability to read a paragraph, identify the difference between the key points and details, and communicate to the user a summarized response of only relevant points. The reply does pass the vibe check, the output was a summarized version of the larger article in a clear and concise format. Even though I didn't specify the length of the summary needed the original article was around 600 words and the output was 135 words. The response was separated into three distinct key ideas focused on the main requirements of who, what, where, and when. Also, the overall format was easy to read. 

    What could make the application better: There could be better flow and removal of some redundancies, such as repeating the voting concept in all three sections. Perhaps, having a cleaner prioritization of the materials, i.e. dates and contest information first then talking to the bear's ecological standings. 


3. Write a short, imaginative story (100–150 words) about a robot finding friendship in an unexpected place.
    - Aspect Tested: 
         This question is testing if the application can generate an imaginative story about a specific subject matter within a certain number of words. The application did pass the vibe check, it was able to create a story about a robot finding an unlikely friendship with a bird that it helped. It gives the user (at least for me) an emotional response of feeling sad or disheartened by the Robot's loneliness to a heartwarming feeling by the end. There was a clear start to end flow which was easy for the audience to follow along. Also, there were good details that aided to the reading experience, such as "in a quiet junkyard" or "trapped beneath broken wires" that helped build the story. It was also 124 words, within the limit. 
    


    What could make this application better: The response fit what the prompt was. Perhaps adding leading questions on how to tune the response, such as do you want more suspense, or do you want a different tone? 

4. If a store sells apples in packs of 4 and oranges in packs of 3, how many packs of each do I need to buy to get exactly 12 apples and 9 oranges?
    - Aspect Tested:
    
    This question is testing if the application can basic math from a given scenario. The response does pass the vibe check. It starts by stating what it is looking for (12 apples and 9 oranges) and continues to do the calculations for the user step by step. The final answer is correct (3 packs of apples and 3 packs of oranges). It generally is easy to follow and is readable. 

    What could make the application better: The formatting needs work. The simple calculations could be cleaner looking (not using plain text and markdown formats). Also, there could be a thought explanation of the process too. 


5. Rewrite the following paragraph in a professional, formal tone…
    - Aspect Tested:

    This question is testing if the application can adapt an informal style paragraph into a formal / professional piece. Therefore, the response needed to be polished (correct spelling, grammar, and organization), while retaining the message of the original text. The response did pass the vibe check. All the slang and poorly written sentences was changed to be more professional. The ideas were also structured in a more organized way and redundancies were removed. 
    
    What could make the application better: The tone is slightly different now that it is more professional. Potentially ensuring that those feelings are still translated better could be an area of improvement. The same messaged though was received.


This "vibe check" now serves as a baseline, of sorts, to help understand what holes your application has.

#### A Note on Vibe Checking

>"Vibe checking" is an informal term for cursory unstructured and non-comprehensive evaluation of LLM-powered systems. The idea is to loosely evaluate our system to cover significant and crucial functions where failure would be immediately noticeable and severe.
>
>In essence, it's a first look to ensure your system isn't experiencing catastrophic failure.

#### ❓Question #1:

What are some limitations of vibe checking as an evaluation tool?
##### ✅ Answer:

Vibe checking is essentially doing a sniff test or sanity check on the application (similar to what you do with calculations). The main point is to quickly identify blatant issues or areas for improvement without spending a lot of time on a full evaluation.Although necessary, it has drawbacks—especially if you rely on it exclusively for a production system. 

The main limitations are:
    - Subjectivity: Evaluations depend on the individual. One person may deem a response good, while another may find it poor.
    - Lack of objective metrics: Vibe checking does not measure accuracy, correctness, or validity.
    - Surface level: Cannot fix deeper issues and only looks at surface level elements 
    
Overall, vibe checking is useful for an initial assessment of format, task completion, and general functionality. However, to ensure responses are accurate, logically sound, and free from hallucinations, a deeper evaluation is required.


### 🚧 Advanced Build (OPTIONAL):

Please make adjustments to your application that you believe will improve the vibe check you completed above, then deploy the changes to your Vercel domain [(see these instructions from your Challenge project)](https://github.com/AI-Maker-Space/The-AI-Engineer-Challenge/blob/main/README.md) and redo the above vibe check.

> NOTE: You may reach for improving the model, changing the prompt, or any other method.

#### 🏗️ Activity #1
##### Adjustments Made:
- _describe adjustment(s) here_

After a thorough vibe check, a lot of key improvements were made to significantly enhance the app and make it more reliable and transparent. The first, was bettering the memory functionality, user interface, and the overall user experience. The application's memory system now retains conversation history across sessions, supporting a 20-message context window. Before the application could not remember previous information and would be wiped clean from one message to the next. This change allows the AI to reference and build on previous parts of the conversation more effectively. The UI also received a major upgrade, including a cleaner dual-panel design with a natural, chat-style main window and a collapsible AI analysis panel that shows the reasoning behind responses and offers follow-up questions to keep conversations engaging. This gives users more confidence when using the app, by seeing how the app came up with the reply or what key words it was using the prompt. This can also be hidden if the user just wants to use the normal chatbot interface. 

Dark mode was improved with better contrast and more readable fonts—black text in light mode and white in dark mode—for a more accessible experience. The refresh bar, which previously caused visual distortion every 5 seconds, was removed, and the entire interface was made more responsive and live looking (No refreshing bars). Also added an indicator whent he app is thinking in the meanwhile, so that users don't feel it is a black box and the answer is note pending. The issue is that people might get annoyed they cannot type in the meanwhile, but it is worth this annoyance to have a cleaner interface and better communication of process with the user.  Real-time statistics are now available, showing memory usage, message count, and session duration. Users cancancan also export their conversation history as a JSON file in case they want to recall or do analysis on it (adding transparency) and easily clear all stored history through a new button in the settings.

Behind the scenes, the system prompt was made more comprehensive, message formatting was refined, and error handling was improved to ensure smoother, more reliable interactions. Additional features include structured responses, confidence indicators (so the AI can express uncertainty), and enhanced chain-of-thought reasoning to make the AI’s thought process more transparent. Overall, this version takes the basic structure of the original build and transforms it into a far more polished, intuitive, and intelligent experience for the user.

Hope you all like it!

Old app: https://frontend-nine-sage-81.vercel.app/
New app: https://enhanced-nature-ai.vercel.app/



    #### Results:
 _Comment here how the change(s) impacted the vibe check of your system_
1. Was able to pass vibe test, but the answer was longer and more detailed than before. Still uses an analogy but may be more confusing due to the increased detail. What was better though was the reasoning panel explained how it got to that conclusion (giving the user some piece of mind that what they were requesting was what the chatbot understood). Also, the leading questions are helpful, asking does these analogies make sense to you? or would you like to know how to use OOP in a real-world application (furthering your knowledge). I was also able to ask it more questions to make it shorter and simpler due to the memory enhancements. So, I was able to prompt it better and get a cleaner result. 
2. Slightly better flow for the article and less redundancies (i.e. did not say to vote 3 separate times). Still need to be better at organizing the thoughts, but overall cohesive. Was also able to see reasoning and the follow-up questions are helpful. Was able to follow up the response by asking for a 1 sentence summary, which a smidge to long captured all the key elements. 
3. Passed vibe check, created a good story that was like the original application. The only difference was having the reasoning there to explain how it got to that story. In this case it says it wanted to create a contrast between the industrial world and freedom of nature. So, in this case, I can see the angle more where it was coming from, and I can now edit the story from that. I can also ask some of the leading follow ups. 
4. There was great improvement on the math question. It gave a lot more information for reasoning and answered the question in a step-by-step process. The formatting was also a lot cleaner

old answer: 

To get exactly 12 apples and 9 oranges:

        - Apples come in packs of 4, so:  
        \( \frac{12}{4} = 3 \) packs of apples.

        - Oranges come in packs of 3, so:  
        \( \frac{9}{3} = 3 \) packs of oranges.

**You need 3 packs of apples and 3 packs of oranges.**


new answer: 
        To get exactly 12 apples and 9 oranges, you can calculate the number of packs needed for each fruit.
        - For apples: Since each pack contains 4 apples, you would divide 12 by 4. That gives you 3 packs of apples (12 ÷ 4 = 3).
        - For oranges: Each pack has 3 oranges, so dividing 9 by 3 gives you 3 packs of oranges (9 ÷ 3 = 3).
        So, you need to buy 3 packs of apples and 3 packs of oranges.

5. Passed vibe test, wasn't that much more improvement to the answer. But the reasoning and questions were helpful. 


## Submitting Your Homework
### Main Assignment (Activity #1 only)
Follow these steps to prepare and submit your homework:
1. Pull the latest updates from upstream into the main branch of your AIE8 repo:
    - For your initial repo setup see [00_Setting Up Git/README.md](https://github.com/AI-Maker-Space/AIE8/tree/main/00_Setting%20Up%20Git)
    - To get the latest updates from AI Makerspace into your own AIE8 repo, run the following commands:
    ```
    git checkout main
    git pull upstream main
    git push origin main
    ```
2. **IMPORTANT:** Start Cursor from the `01_Prototyping Best Practices & Vibe Check` folder (you can also use the _File -> Open Folder_ menu option of an existing Cursor window)
3. Create a branch of your `AIE8` repo to track your changes. Example command: `git checkout -b s01-assignment`
4. Edit this `README.md` file (the one in your `AIE8/01_Prototyping Best Practices & Vibe Check` folder)
5. Perform a "Vibe check" evaluation your AI-Engineering-Challenge system using the five questions provided above 
6. For each Activity question:
    - Define the “Aspect Tested”
    - Comment on how your system performed on it. 
7. Provide an answer to `❓Question #1:` after the `✅ Answer:` prompt
8. Add, commit and push your modified `README.md` to your origin repository.

>(NOTE: You should not merge the new document into origin's main branch. This will spare you from update challenges for each future session.)

When submitting your homework, provide the GitHub URL to the tracking branch (for example: `s01-assignment`) you created on your AIE8 repo.

### The Advanced Build:
1. Follow all of the steps (Steps 1 - 8) of the Main Assignment above
2. Document what you changed and the results you saw in the `Adjustments Made:` and `Results:` sections of the Advanced Build's Assignment #1
3. Add, commit and push your additional modifications to this `README.md` file to your origin repository.

When submitting your homework, provide the following on the form:
+ The GitHub URL to the tracking branch (for example: `s01-assignment`) you created on your AIE8 repo.
+ The public Vercel URL to your updated Challenge project on your AIE8 repo.
